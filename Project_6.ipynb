{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reading the train csv file.\n",
    "\n",
    "income_train=pd.read_csv('income_data_train.csv')\n",
    "income_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "income_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reading the test csv file.\n",
    "income_test=pd.read_csv('income_data_test.csv')\n",
    "income_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "income_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "income_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating income dataset.\n",
    "1. Since both income train and test data are having same dimensions, creating single dataset for it.\n",
    "2. Also some of the columns having ? as well as spaces and . characters which needs clean-up.\n",
    "3. Many of the required columns are of type objects which require transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Concat train and test dataframes\n",
    "data=pd.concat([income_train,income_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Trimming spacing in the data from start and end of string across all the data in dataframe.\n",
    "data.replace('^\\s+', '', regex=True, inplace=True) #front\n",
    "data.replace('\\s+$', '', regex=True, inplace=True) #end\n",
    "\n",
    "\n",
    "# Replacing . in the data['income'] column.\n",
    "data['income'].replace(to_replace=\"<=50K.\",value =\"<=50K\", inplace=True)\n",
    "data['income'].replace(to_replace=\">50K.\",value =\">50K\", inplace=True)\n",
    "\n",
    "#Replacing the value ? with other values.\n",
    "data['workclass'].replace(to_replace =\"?\",value ='State-gov', inplace=True)\n",
    "data['occupation'].replace(to_replace =\"?\",value ='Tech-support', inplace=True)\n",
    "data['native-country'].replace(to_replace =\"?\",value =\"India\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#count plot on workclass \n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.countplot(x='workclass', hue='income',data=data)\n",
    "#sns.countplot(x='workclass',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#count plot on occupation\n",
    "plt.figure(figsize=(25,5))\n",
    "sns.countplot(x='occupation', hue='income',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding columns as part of transformation.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "le= LabelEncoder()\n",
    "\n",
    "data['workclass'] = le.fit_transform(data['workclass'])\n",
    "data['education'] = le.fit_transform(data['education'])\n",
    "data['marital-status'] = le.fit_transform(data['marital-status'])\n",
    "\n",
    "data['occupation'] = le.fit_transform(data['occupation'])\n",
    "data['relationship'] = le.fit_transform(data['relationship'])\n",
    "\n",
    "data['race'] = le.fit_transform(data['race'])\n",
    "data['sex'] = le.fit_transform(data['sex'])\n",
    "data['native-country'] = le.fit_transform(data['native-country'])\n",
    "data['income'] = le.fit_transform(data['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the zscore in order to normalize the data.\n",
    "\n",
    "from scipy.stats import zscore\n",
    "z= np.abs(zscore(data))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying for the presence of zscore value of data with threshold of more than 3 std score.\n",
    "\n",
    "threshold=3\n",
    "print(np.where(z>3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the outliers having zscore value of more than 3.\n",
    "income=data[(z<3).all(axis=1)]\n",
    "income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed  records from the original data of  set where zscore was more than 3 and created a new set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10)) \n",
    "sns.heatmap(income.corr(), annot=True, fmt=\".2f\") \n",
    "plt.suptitle(\"Correlation Map\", fontsize=18)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for skewed data\n",
    "income.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing the skewness with boxcox1p in order to avoid 0 encountered as negative while transformation.\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "# 0 -> log transform\n",
    "# .5 -> square root transform\n",
    "\n",
    "\n",
    "income['capital-gain']=boxcox1p(income['capital-gain'],0.5)\n",
    "income['capital-loss']=boxcox1p(income['capital-loss'],0.5)\n",
    "income['income']=boxcox1p(income['income'],0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting x  by excluding income column which is y here for prediction.\n",
    "x=data.drop(['income'],axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "#scale = MinMaxScaler()\n",
    "\n",
    "x=scale.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settng Y\n",
    "y=data['income']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc_score=0\n",
    "for r_state in range(42,101):\n",
    "    train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=.21,random_state=r_state)\n",
    "    lg=LogisticRegression()\n",
    "    lg.fit(train_x,train_y)\n",
    "    pred=lg.predict(test_x)\n",
    "    accuracyScore=accuracy_score(test_y,pred)\n",
    "    #print(\"Accuracy_Score corresponding to r_state: \",r_state,\" is \",accuracyScore)\n",
    "    if(accuracyScore>max_acc_score):\n",
    "        max_acc_score=accuracyScore\n",
    "        final_rstate=r_state\n",
    "        \n",
    "print(\"\\n\\n\")\n",
    "print(\"Max_accuracy_Score corresponding to final_r_state: \",final_rstate,\" is \",max_acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the test x & y values and using the random state from above step which is 74.\n",
    "\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=.21,random_state=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=LogisticRegression()\n",
    "DT=DecisionTreeClassifier()\n",
    "GNB=GaussianNB()\n",
    "RFC=RandomForestClassifier(n_estimators=100,random_state=100)\n",
    "ADC=AdaBoostClassifier(n_estimators=500,random_state=10)\n",
    "GBC=GradientBoostingClassifier(n_estimators=500,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "models.append(('LogisticRegression',LR))\n",
    "models.append(('DecisionTreeClassifier',DT))\n",
    "models.append(('GaussianNB',GNB))\n",
    "models.append(('RandomForestClassifier',RFC))\n",
    "models.append(('AdaBoostClassifier',ADC))\n",
    "models.append(('GradientBoostingClassifier',GBC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model=[]\n",
    "score=[]\n",
    "cvs=[]\n",
    "rocscore=[]\n",
    "\n",
    "for name,model in models:\n",
    "    print(\"--------------\",name,\"--------------\")\n",
    "    Model.append(name)\n",
    "    model.fit(train_x,train_y)\n",
    "    print(model)\n",
    "    pre=model.predict(test_x)\n",
    "    AS=accuracy_score(test_y,pre)\n",
    "    print(\"Accuracy Score: \", AS)\n",
    "    score.append(AS*100)\n",
    "    sc=cross_val_score(model,x,y,cv=10,scoring='accuracy').mean()\n",
    "    print(\"Cross_Val_Score: \", sc)\n",
    "    cvs.append(sc*100)\n",
    "    cm=confusion_matrix(test_y,pre)\n",
    "    print(cm)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame({\"Model\": Model, \"Score\": score, \"Cross Val Score\":cvs})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the above table GradientBoostingRegressor seems to be the best model with over 87% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the prediction data in a file.\n",
    "\n",
    "predictData=pd.DataFrame(pre)\n",
    "data.to_csv('income_Predict.csv')\n",
    "predictData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(GBC,\"GBC_Income.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
