{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file.\n",
    "\n",
    "df0=pd.read_csv('auto-mpg.data-original', delim_whitespace=True, names=('mpg','cylinders','displacement','horsepower','weight','acceleration','model_year','origin','car_name'))\n",
    "#names=('mpg','cylinders','displacement','horsepower','weight','acceleration','model_year','origin','car_name'))\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking which all columns have null values\n",
    "\n",
    "df0.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the nan or nulls\n",
    "\n",
    "df0['mpg'].fillna(df0['mpg'].median(), inplace=True)\n",
    "df0['horsepower'].fillna(df0['horsepower'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null using HeatMap\n",
    "sns.heatmap(df0.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding columns as part of transformation.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "le= LabelEncoder()\n",
    "\n",
    "#df = le.fit_transform(df0)\n",
    "df0['car_name'] = le.fit_transform(df0['car_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10)) \n",
    "sns.heatmap(df0.corr(), annot=True, fmt=\".2f\") \n",
    "plt.suptitle(\"Correlation Map\", fontsize=18)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the zscore in order to normalize the data.\n",
    "\n",
    "from scipy.stats import zscore\n",
    "z= np.abs(zscore(df0))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying for the presence of zscore value of data with threshold of more than 3 std score.\n",
    "\n",
    "threshold=3\n",
    "print(np.where(z>3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the outliers having zscore value of more than 3.\n",
    "data=df0[(z<3).all(axis=1)]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed 6 records from the original data of 406 set where zscore was more than 3 and created a new set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for skewed data\n",
    "data.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting x  by excluding AveragePrice column which is y here for prediction.\n",
    "x=data.drop(['mpg'],axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "#scale = MinMaxScaler()\n",
    "x=scale.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settng Y\n",
    "\n",
    "y=data['mpg']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_score=0\n",
    "for r_state in range(42,101):\n",
    "    train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=.25,random_state=r_state)\n",
    "    lm=LinearRegression()\n",
    "    lm.fit(train_x,train_y)\n",
    "    pred=lm.predict(test_x)\n",
    "    score=lm.score(x,y)\n",
    "    #print(\"Score corresponding to r_state: \",r_state,\" is \",score)\n",
    "    if(score>max_score):\n",
    "        max_score=score\n",
    "        final_rstate=r_state\n",
    "        \n",
    "print(\"\\n\")\n",
    "print(\"Max_accuracy_Score corresponding to final_r_state: \",final_rstate,\" is \",max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the test x & y values and using the random state from above step which is 51.\n",
    "\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=.25,random_state=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Lasso,Ridge,ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN=KNeighborsRegressor(n_neighbors=10)\n",
    "SV=SVR()\n",
    "LR=LinearRegression()\n",
    "DT=DecisionTreeRegressor(random_state=10)\n",
    "LS = Lasso(alpha=0.001)\n",
    "RD = Ridge(alpha=0.01)\n",
    "EL = ElasticNet(alpha=0.001)\n",
    "RF = RandomForestRegressor(n_estimators=200,random_state=92)\n",
    "AD = AdaBoostRegressor()\n",
    "GB = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "models.append(('KNeighborsRegressor',KNN))\n",
    "models.append(('SVR',SV))\n",
    "models.append(('LinearRegression',LR))\n",
    "models.append(('DecisionTreeRegressor',DT))\n",
    "models.append(('Lasso',LS))\n",
    "models.append(('Ridge',RD))\n",
    "models.append(('ElasticNet',EL))\n",
    "models.append(('RandomForestRegressor',RF))\n",
    "models.append(('AdaBoostRegressor',AD))\n",
    "models.append(('GradientBoostingRegressor',GB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model=[]\n",
    "score=[]\n",
    "mae=[]\n",
    "mse=[]\n",
    "rmae=[]\n",
    "\n",
    "for name,model in models:\n",
    "    print(\"--------------\",name,\"--------------\")\n",
    "    Model.append(name)\n",
    "    model.fit(train_x,train_y)\n",
    "    print(model)\n",
    "    pre=model.predict(test_x)\n",
    "    \n",
    "    # Metrics\n",
    "    m1=mean_absolute_error(test_y,pred)\n",
    "    print(\"Mean absolute error\",m1)\n",
    "    mae.append(m1)\n",
    "           \n",
    "    m2=mean_squared_error(test_y,pred)\n",
    "    print(\"Mean squared error\",m2)\n",
    "    mse.append(m2)\n",
    "    \n",
    "    \n",
    "    m3=np.sqrt(mean_squared_error(test_y,pred))\n",
    "    print(\"Root Mean absolute error\",m3)\n",
    "    rmae.append(m3)\n",
    "    \n",
    "    #Model performance\n",
    "    modelscore=model.score(test_x,test_y)\n",
    "    print(\"Score: \",modelscore )\n",
    "    score.append(modelscore*100)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame({\"Model\": Model, \"Score\": score})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the above table RandomForestRegressor & GradientBoostingRegressor seems to be the models with over 86% accuracy.\n",
    "\n",
    "Selecting the best model using GridSearchCV check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#parameters \n",
    "params={'n_estimators':[100,500],'random_state':[10,100]}\n",
    "\n",
    "\n",
    "rf= GridSearchCV(RandomForestRegressor(),param_grid=params)\n",
    "rf.fit(train_x,train_y)\n",
    "print(\"Best parameters for RandomForest: \",rf.best_params_)\n",
    "\n",
    "gb= GridSearchCV(GradientBoostingRegressor(),param_grid=params)\n",
    "gb.fit(train_x,train_y)\n",
    "print(\"Best parameters for GradientBoostingRegressor: \",gb.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestRegressor(n_estimators=500,random_state=10)\n",
    "GB = GradientBoostingRegressor(n_estimators=100,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "\n",
    "models.append(('RandomForestRegressor',RF))\n",
    "models.append(('GradientBoostingRegressor',GB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model=[]\n",
    "score=[]\n",
    "mae=[]\n",
    "mse=[]\n",
    "rmae=[]\n",
    "\n",
    "for name,model in models:\n",
    "    print(\"--------------\",name,\"--------------\")\n",
    "    Model.append(name)\n",
    "    model.fit(train_x,train_y)\n",
    "    print(model)\n",
    "    pre=model.predict(test_x)\n",
    "    \n",
    "    # Metrics\n",
    "    m1=mean_absolute_error(test_y,pred)\n",
    "    print(\"Mean absolute error\",m1)\n",
    "    mae.append(m1)\n",
    "           \n",
    "    m2=mean_squared_error(test_y,pred)\n",
    "    print(\"Mean squared error\",m2)\n",
    "    mse.append(m2)\n",
    "    \n",
    "    \n",
    "    m3=np.sqrt(mean_squared_error(test_y,pred))\n",
    "    print(\"Root Mean absolute error\",m3)\n",
    "    rmae.append(m3)\n",
    "    \n",
    "    #Model performance\n",
    "    modelscore=model.score(test_x,test_y)\n",
    "    print(\"Score: \",modelscore )\n",
    "    score.append(modelscore*100)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame({\"Model\": Model, \"Score\": score})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingRegressor is the best fit model with better accuracy of 86.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the prediction data in a file.\n",
    "\n",
    "predictData=pd.DataFrame(pre)\n",
    "data.to_csv('AutoMPG_Predict.csv')\n",
    "predictData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(GB,\"GB_AutoMPG.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
